{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Feature Extraction\n",
    "\n",
    "### Bag of Words\n",
    "\n",
    "  \n",
    "1. Term Frequency  \n",
    "tf = 1 / x.sum(axis=1)[;, None]  \n",
    "x = x * tf  \n",
    "sklearn.feature_extraction.text.CountVectorizer  \n",
    "Sum of each row is equal to 1.  \n",
    "  \n",
    "  \n",
    "2. Inverse Document Frequency.   \n",
    "idf = np.log(x.shape[0] / (x > 0).sum(0))  \n",
    "x = x * idf  \n",
    "This will decrease the significance of widespread words in the dataset and do require feature scaling.  \n",
    "sklearn.feature_extraction.text.TfidfVectrizer  \n",
    "Normalized column wise.\n",
    "\n",
    "### n-grams\n",
    "\n",
    "Add not only columns coresponding to the word, but also columns coresponding to n consequent words.  \n",
    "sklearn.feature_extraction.text.CountVectorizer(Ngram_range, analyzer) (analyzer can change from word n-grams to char n-grams).  \n",
    "\n",
    "### Text Preprocessing Before Extraction\n",
    "\n",
    "1. Lowercase. (CountVectorizer would do this defautly).  \n",
    "2. Lemmatization (example: cars -> car, had -> have).  \n",
    "3. Stemming (example: democracy, democratic and democratization -> democr)  \n",
    "4. Stopwords  (sklearn.feature_extraction.text.CountVectorizer(max_df).  \n",
    "   a word with frequency exceeding max_df would be removed.\n",
    "\n",
    "## Summary\n",
    "Pipeline of appying BOW\n",
    "1. Preprocessing:  \n",
    "   Lowercase, stemming, lemmatization, stopwords.  \n",
    "2. Ngrams can help to use local context.  \n",
    "3. Postporcessing: TFiDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "Words: Word2vec, Glove, FastText, etc   \n",
    "Sentences: Doc2vec, etc   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW and W2V Comparison \n",
    "1. Bag of Words.  \n",
    "  a. Very large vectors.  \n",
    "  b. Meaning of each value in vector is known.  \n",
    "2. Word2Vec   \n",
    "  a. Relatively small vectors.  \n",
    "  b. Values in vector can be interpreted only in some cases.  \n",
    "  c. The words with similar meaning often have similar embeddings.  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images\n",
    "### Data Augmentation  (example: Rotation)\n",
    "\n",
    "### Use pretrained-CNN-Models to do feature extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
